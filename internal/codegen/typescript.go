package codegen

import (
	"fmt"
	"strings"

	"github.com/watzon/alyx/internal/schema"
)

// TypeScriptGenerator generates TypeScript client code.
type TypeScriptGenerator struct {
	cfg *Config
}

// NewTypeScriptGenerator creates a new TypeScript generator.
func NewTypeScriptGenerator(cfg *Config) *TypeScriptGenerator {
	return &TypeScriptGenerator{cfg: cfg}
}

// Language returns the target language.
func (g *TypeScriptGenerator) Language() Language {
	return LanguageTypeScript
}

// Generate produces TypeScript client code from a schema.
func (g *TypeScriptGenerator) Generate(s *schema.Schema) ([]GeneratedFile, error) {
	var files []GeneratedFile

	// Generate types file
	typesContent := g.generateTypes(s)
	files = append(files, GeneratedFile{
		Path:    "types.ts",
		Content: typesContent,
	})

	// Generate client file
	clientContent := g.generateClient(s)
	files = append(files, GeneratedFile{
		Path:    "client.ts",
		Content: clientContent,
	})

	// Generate index file
	indexContent := g.generateIndex()
	files = append(files, GeneratedFile{
		Path:    "index.ts",
		Content: indexContent,
	})

	return files, nil
}

func (g *TypeScriptGenerator) generateTypes(s *schema.Schema) string {
	var b strings.Builder

	b.WriteString("// Generated by Alyx - DO NOT EDIT\n\n")

	// Generate interface for each collection
	for _, name := range sortedCollectionNames(s) {
		coll := s.Collections[name]
		g.generateCollectionInterface(&b, name, coll)
		b.WriteString("\n")
	}

	// Generate create/update input types
	for _, name := range sortedCollectionNames(s) {
		coll := s.Collections[name]
		g.generateInputTypes(&b, name, coll)
		b.WriteString("\n")
	}

	return b.String()
}

func (g *TypeScriptGenerator) generateCollectionInterface(b *strings.Builder, name string, coll *schema.Collection) {
	typeName := toPascalCase(name)

	b.WriteString(fmt.Sprintf("/** %s document type. */\n", typeName))
	b.WriteString(fmt.Sprintf("export interface %s {\n", typeName))

	for _, field := range coll.OrderedFields() {
		// Skip internal fields in client types
		if field.Internal {
			continue
		}

		tsType := field.Type.TypeScriptType(field.Nullable)
		optional := ""
		if field.Nullable {
			optional = "?"
		}

		// Add JSDoc comment for field if it has validation
		if field.Validate != nil || field.References != "" {
			b.WriteString(fmt.Sprintf("  /** %s */\n", g.fieldDoc(field)))
		}

		b.WriteString(fmt.Sprintf("  %s%s: %s;\n", field.Name, optional, tsType))
	}

	// Add expanded relation fields
	for _, field := range coll.OrderedFields() {
		if table, _, ok := field.ParseReference(); ok {
			refType := toPascalCase(table)
			b.WriteString(fmt.Sprintf("  /** Expanded %s relation. */\n", field.Name))
			b.WriteString(fmt.Sprintf("  %s_expanded?: %s;\n", field.Name, refType))
		}
	}

	b.WriteString("}\n")
}

func (g *TypeScriptGenerator) generateInputTypes(b *strings.Builder, name string, coll *schema.Collection) {
	typeName := toPascalCase(name)

	// Create input type (exclude auto-generated fields)
	b.WriteString(fmt.Sprintf("/** Input for creating a %s. */\n", typeName))
	b.WriteString(fmt.Sprintf("export interface %sCreateInput {\n", typeName))

	for _, field := range coll.OrderedFields() {
		if field.Internal {
			continue
		}
		// Skip primary key with auto default, and auto timestamps
		if field.Primary && field.IsAutoGenerated() {
			continue
		}
		if field.IsTimestampNow() || field.IsAutoUpdateTimestamp() {
			continue
		}

		tsType := field.Type.TypeScriptType(false)
		optional := ""
		if field.Nullable || field.HasDefault() {
			optional = "?"
		}

		b.WriteString(fmt.Sprintf("  %s%s: %s;\n", field.Name, optional, tsType))
	}

	b.WriteString("}\n\n")

	// Update input type (all fields optional)
	b.WriteString(fmt.Sprintf("/** Input for updating a %s. */\n", typeName))
	b.WriteString(fmt.Sprintf("export interface %sUpdateInput {\n", typeName))

	for _, field := range coll.OrderedFields() {
		if field.Internal {
			continue
		}
		// Skip primary key and auto-update timestamps
		if field.Primary {
			continue
		}
		if field.IsAutoUpdateTimestamp() {
			continue
		}

		tsType := field.Type.TypeScriptType(false)
		b.WriteString(fmt.Sprintf("  %s?: %s;\n", field.Name, tsType))
	}

	b.WriteString("}\n")
}

func (g *TypeScriptGenerator) fieldDoc(field *schema.Field) string {
	var parts []string

	if field.References != "" {
		parts = append(parts, fmt.Sprintf("References %s", field.References))
	}

	if field.Validate != nil {
		if field.Validate.MinLength != nil {
			parts = append(parts, fmt.Sprintf("minLength: %d", *field.Validate.MinLength))
		}
		if field.Validate.MaxLength != nil {
			parts = append(parts, fmt.Sprintf("maxLength: %d", *field.Validate.MaxLength))
		}
		if field.Validate.Min != nil {
			parts = append(parts, fmt.Sprintf("min: %v", *field.Validate.Min))
		}
		if field.Validate.Max != nil {
			parts = append(parts, fmt.Sprintf("max: %v", *field.Validate.Max))
		}
		if field.Validate.Format != "" {
			parts = append(parts, fmt.Sprintf("format: %s", field.Validate.Format))
		}
		if len(field.Validate.Enum) > 0 {
			parts = append(parts, fmt.Sprintf("enum: [%s]", strings.Join(field.Validate.Enum, ", ")))
		}
	}

	if len(parts) == 0 {
		return field.Name
	}
	return strings.Join(parts, ", ")
}

func (g *TypeScriptGenerator) generateClient(s *schema.Schema) string {
	var b strings.Builder

	b.WriteString("// Generated by Alyx - DO NOT EDIT\n\n")

	// Import types
	b.WriteString("import type {\n")
	for _, name := range sortedCollectionNames(s) {
		typeName := toPascalCase(name)
		b.WriteString(fmt.Sprintf("  %s,\n", typeName))
		b.WriteString(fmt.Sprintf("  %sCreateInput,\n", typeName))
		b.WriteString(fmt.Sprintf("  %sUpdateInput,\n", typeName))
	}
	b.WriteString("} from './types';\n\n")

	if len(s.Buckets) > 0 {
		g.generateStorageTypes(&b)
		g.generateStorageClient(&b)
	}

	// Filter operators type
	b.WriteString(`/** Filter operators for queries. */
export type FilterOperator = 'eq' | 'ne' | 'gt' | 'gte' | 'lt' | 'lte' | 'like' | 'in' | 'contains';

/** Filter value with operator. */
export type FilterValue<T> = T | { [K in FilterOperator]?: T };

/** Query options for list operations. */
export interface QueryOptions<T> {
  filter?: Partial<{ [K in keyof T]: FilterValue<T[K]> }>;
  sort?: string | string[];
  limit?: number;
  offset?: number;
  expand?: string[];
}

/** Paginated response. */
export interface PaginatedResponse<T> {
  items: T[];
  total: number;
  page: number;
  perPage: number;
}

/** Subscription callback. */
export type SubscriptionCallback<T> = (event: {
  type: 'snapshot' | 'insert' | 'update' | 'delete';
  data: T | T[];
}) => void;

/** Alyx client configuration. */
export interface AlyxClientConfig {
  url: string;
  token?: string;
}

`)

	// Collection class
	b.WriteString(`/** Collection provides CRUD operations for a specific collection. */
export class Collection<T, TCreate, TUpdate> {
  constructor(
    private client: AlyxClient,
    private name: string,
  ) {}

  /** List documents with optional filtering. */
  async list(options?: QueryOptions<T>): Promise<PaginatedResponse<T>> {
    const params = this.buildQueryParams(options);
    return this.client.request<PaginatedResponse<T>>(` + "`" + `GET /api/collections/${this.name}?${params}` + "`" + `);
  }

  /** Get a single document by ID. */
  async get(id: string, expand?: string[]): Promise<T> {
    const params = expand?.length ? ` + "`" + `?expand=${expand.join(',')}` + "`" + ` : '';
    return this.client.request<T>(` + "`" + `GET /api/collections/${this.name}/${id}${params}` + "`" + `);
  }

  /** Create a new document. */
  async create(data: TCreate): Promise<T> {
    return this.client.request<T>(` + "`" + `POST /api/collections/${this.name}` + "`" + `, { body: data });
  }

  /** Update an existing document. */
  async update(id: string, data: TUpdate): Promise<T> {
    return this.client.request<T>(` + "`" + `PATCH /api/collections/${this.name}/${id}` + "`" + `, { body: data });
  }

  /** Delete a document. */
  async delete(id: string): Promise<void> {
    return this.client.request<void>(` + "`" + `DELETE /api/collections/${this.name}/${id}` + "`" + `);
  }

  /** Subscribe to changes in this collection. */
  subscribe(
    callback: SubscriptionCallback<T>,
    options?: QueryOptions<T>,
  ): () => void {
    return this.client.subscribe(this.name, callback, options);
  }

  private buildQueryParams(options?: QueryOptions<T>): string {
    if (!options) return '';
    const params = new URLSearchParams();

    if (options.filter) {
      for (const [key, value] of Object.entries(options.filter)) {
        if (value !== undefined) {
          if (typeof value === 'object' && value !== null) {
            for (const [op, v] of Object.entries(value)) {
              params.append('filter', ` + "`" + `${key}:${op}:${v}` + "`" + `);
            }
          } else {
            params.append('filter', ` + "`" + `${key}:eq:${value}` + "`" + `);
          }
        }
      }
    }

    if (options.sort) {
      const sorts = Array.isArray(options.sort) ? options.sort : [options.sort];
      for (const s of sorts) {
        params.append('sort', s);
      }
    }

    if (options.limit) params.set('limit', String(options.limit));
    if (options.offset) params.set('offset', String(options.offset));
    if (options.expand?.length) params.set('expand', options.expand.join(','));

    return params.toString();
  }
}

`)

	// Auth types
	b.WriteString(`/** Auth credentials for login. */
export interface LoginCredentials {
  email: string;
  password: string;
}

/** Auth response with tokens. */
export interface AuthResponse {
  access_token: string;
  refresh_token: string;
  user: {
    id: string;
    email: string;
    role: string;
    verified: boolean;
    metadata?: Record<string, unknown>;
  };
}

/** Registration data. */
export interface RegisterData {
  email: string;
  password: string;
  name?: string;
  metadata?: Record<string, unknown>;
}

`)

	// Main client class
	b.WriteString(`/** Subscription event from WebSocket. */
export interface SubscriptionEvent<T = unknown> {
  type: 'snapshot' | 'insert' | 'update' | 'delete';
  data: T | T[];
}

/** Alyx client for interacting with the Alyx API. */
export class AlyxClient {
  private url: string;
  private token?: string;
  private ws?: WebSocket;
  private subscriptions = new Map<string, Set<(event: SubscriptionEvent) => void>>();

  constructor(config: AlyxClientConfig) {
    this.url = config.url.replace(/\/$/, '');
    this.token = config.token;
  }

  /** Set the auth token. */
  setToken(token: string | undefined): void {
    this.token = token;
  }

  /** Make an HTTP request to the API. */
  async request<T>(
    endpoint: string,
    options?: { body?: unknown },
  ): Promise<T> {
    const [method, ...pathParts] = endpoint.split(' ');
    const path = pathParts.join(' ');

    const headers: Record<string, string> = {
      'Content-Type': 'application/json',
    };
    if (this.token) {
      headers['Authorization'] = ` + "`" + `Bearer ${this.token}` + "`" + `;
    }

    const response = await fetch(` + "`" + `${this.url}${path}` + "`" + `, {
      method,
      headers,
      body: options?.body ? JSON.stringify(options.body) : undefined,
    });

    if (!response.ok) {
      const error = await response.json().catch(() => ({}));
      throw new Error(error.message || ` + "`" + `HTTP ${response.status}` + "`" + `);
    }

    if (response.status === 204) {
      return undefined as T;
    }

    return response.json();
  }

  /** Subscribe to collection changes via WebSocket. */
  subscribe<T>(
    collection: string,
    callback: SubscriptionCallback<T>,
    _options?: unknown,
  ): () => void {
    this.ensureWebSocket();

    const key = collection;
    if (!this.subscriptions.has(key)) {
      this.subscriptions.set(key, new Set());
    }
    this.subscriptions.get(key)!.add(callback as (event: SubscriptionEvent) => void);

    // Send subscribe message
    this.ws?.send(JSON.stringify({
      type: 'subscribe',
      payload: { collection },
    }));

    // Return unsubscribe function
    return () => {
      const subs = this.subscriptions.get(key);
      if (subs) {
        subs.delete(callback);
        if (subs.size === 0) {
          this.subscriptions.delete(key);
          this.ws?.send(JSON.stringify({
            type: 'unsubscribe',
            payload: { collection },
          }));
        }
      }
    };
  }

  private ensureWebSocket(): void {
    if (this.ws && this.ws.readyState === WebSocket.OPEN) return;

    const wsUrl = this.url.replace(/^http/, 'ws') + '/api/realtime';
    this.ws = new WebSocket(wsUrl);

    this.ws.onmessage = (event) => {
      const msg = JSON.parse(event.data);
      if (msg.type === 'delta' || msg.type === 'snapshot') {
        const collection = msg.payload?.subscription_id?.split(':')[0];
        const callbacks = this.subscriptions.get(collection);
        if (callbacks) {
          const subscriptionEvent: SubscriptionEvent = {
            type: msg.type === 'snapshot' ? 'snapshot' : (msg.payload?.action || 'update'),
            data: msg.payload?.data,
          };
          for (const cb of callbacks) {
            cb(subscriptionEvent);
          }
        }
      }
    };
  }

  // Auth methods
  auth = {
    /** Login with email and password. */
    login: async (credentials: LoginCredentials): Promise<AuthResponse> => {
      const response = await this.request<AuthResponse>('POST /api/auth/login', {
        body: credentials,
      });
      this.token = response.access_token;
      return response;
    },

    /** Register a new user. */
    register: async (data: RegisterData): Promise<AuthResponse> => {
      const response = await this.request<AuthResponse>('POST /api/auth/register', {
        body: data,
      });
      this.token = response.access_token;
      return response;
    },

    /** Logout the current user. */
    logout: async (): Promise<void> => {
      await this.request<void>('POST /api/auth/logout');
      this.token = undefined;
    },

    /** Refresh the access token. */
    refresh: async (refreshToken: string): Promise<AuthResponse> => {
      const response = await this.request<AuthResponse>('POST /api/auth/refresh', {
        body: { refresh_token: refreshToken },
      });
      this.token = response.access_token;
      return response;
    },
  };

	// Collection accessors
`)

	// Generate collection properties
	for _, name := range sortedCollectionNames(s) {
		typeName := toPascalCase(name)
		propName := toCamelCase(name)
		b.WriteString(fmt.Sprintf("  %s = new Collection<%s, %sCreateInput, %sUpdateInput>(this, '%s');\n",
			propName, typeName, typeName, typeName, name))
	}

	if len(s.Buckets) > 0 {
		b.WriteString("\n  storage = new StorageClient(this);\n")
	}

	b.WriteString("}\n\n")

	// Export default client factory
	b.WriteString(fmt.Sprintf(`/** Create a new Alyx client. */
export function createClient(config?: Partial<AlyxClientConfig>): AlyxClient {
  return new AlyxClient({
    url: config?.url ?? '%s',
    token: config?.token,
  });
}
`, g.cfg.ServerURL))

	return b.String()
}

func (g *TypeScriptGenerator) generateIndex() string {
	return `// Generated by Alyx - DO NOT EDIT

export * from './types';
export * from './client';
`
}

func (g *TypeScriptGenerator) generateStorageTypes(b *strings.Builder) {
	b.WriteString(`/** File metadata from storage. */
export interface FileMetadata {
  id: string;
  bucket: string;
  name: string;
  path: string;
  mime_type: string;
  size: number;
  checksum?: string;
  compressed: boolean;
  compression_type?: string;
  original_size?: number;
  metadata?: Record<string, string>;
  version: number;
  created_at: Date;
  updated_at: Date;
}

/** Options for file upload. */
export interface UploadOptions {
  onProgress?: (progress: number) => void;
  metadata?: Record<string, string>;
}

/** Options for signed URL generation. */
export interface SignedUrlOptions {
  expiry?: string;
  operation?: 'download' | 'view';
}

/** Signed URL response. */
export interface SignedUrl {
  url: string;
  expires_at: string;
}

/** Options for TUS resumable upload. */
export interface TUSOptions extends UploadOptions {
  chunkSize?: number;
}

/** TUS resumable upload handle. */
export interface TUSUpload {
  start(): Promise<FileMetadata>;
  pause(): void;
  resume(): void;
  cancel(): Promise<void>;
  onProgress(callback: (progress: number) => void): void;
}

`)
}

func (g *TypeScriptGenerator) generateStorageClient(b *strings.Builder) {
	b.WriteString(`/** Storage client for file operations. */
export class StorageClient {
  constructor(private client: AlyxClient) {}

  async upload(
    bucket: string,
    file: File | Blob,
    options?: UploadOptions,
  ): Promise<FileMetadata> {
    const formData = new FormData();
    formData.append('file', file);
    
    if (options?.metadata) {
      for (const [key, value] of Object.entries(options.metadata)) {
        formData.append(` + "`" + `metadata[${key}]` + "`" + `, value);
      }
    }

    const response = await fetch(` + "`" + `${this.client['url']}/api/files/${bucket}` + "`" + `, {
      method: 'POST',
      headers: this.client['token'] ? {
        'Authorization': ` + "`" + `Bearer ${this.client['token']}` + "`" + `,
      } : {},
      body: formData,
    });

    if (!response.ok) {
      const error = await response.json().catch(() => ({}));
      throw new Error(error.message || ` + "`" + `HTTP ${response.status}` + "`" + `);
    }

    return response.json();
  }

  async download(bucket: string, fileId: string): Promise<Blob> {
    const response = await fetch(
      ` + "`" + `${this.client['url']}/api/files/${bucket}/${fileId}/download` + "`" + `,
      {
        headers: this.client['token'] ? {
          'Authorization': ` + "`" + `Bearer ${this.client['token']}` + "`" + `,
        } : {},
      },
    );

    if (!response.ok) {
      const error = await response.json().catch(() => ({}));
      throw new Error(error.message || ` + "`" + `HTTP ${response.status}` + "`" + `);
    }

    return response.blob();
  }

  async getUrl(
    bucket: string,
    fileId: string,
    options?: SignedUrlOptions,
  ): Promise<SignedUrl> {
    const params = new URLSearchParams();
    if (options?.expiry) params.set('expiry', options.expiry);
    if (options?.operation) params.set('operation', options.operation);

    const query = params.toString() ? ` + "`" + `?${params}` + "`" + ` : '';
    return this.client.request<SignedUrl>(
      ` + "`" + `GET /api/files/${bucket}/${fileId}/sign${query}` + "`" + `,
    );
  }

  async delete(bucket: string, fileId: string): Promise<void> {
    return this.client.request<void>(` + "`" + `DELETE /api/files/${bucket}/${fileId}` + "`" + `);
  }

  async list(
    bucket: string,
    options?: { limit?: number; offset?: number },
  ): Promise<PaginatedResponse<FileMetadata>> {
    const params = new URLSearchParams();
    if (options?.limit) params.set('limit', String(options.limit));
    if (options?.offset) params.set('offset', String(options.offset));

    const query = params.toString() ? ` + "`" + `?${params}` + "`" + ` : '';
    return this.client.request<PaginatedResponse<FileMetadata>>(
      ` + "`" + `GET /api/files/${bucket}${query}` + "`" + `,
    );
  }

  uploadResumable(
    bucket: string,
    file: File,
    options?: TUSOptions,
  ): TUSUpload {
    const chunkSize = options?.chunkSize || 5 * 1024 * 1024;
    let uploadId: string | null = null;
    let offset = 0;
    let paused = false;
    let canceled = false;
    let progressCallback: ((progress: number) => void) | undefined = options?.onProgress;

    const createUpload = async (): Promise<string> => {
      const metadata: Record<string, string> = {
        filename: file.name,
        filetype: file.type,
        ...options?.metadata,
      };

      const metadataHeader = Object.entries(metadata)
        .map(([k, v]) => ` + "`" + `${k} ${btoa(v)}` + "`" + `)
        .join(',');

      const response = await fetch(
        ` + "`" + `${this.client['url']}/api/files/${bucket}/tus` + "`" + `,
        {
          method: 'POST',
          headers: {
            'Upload-Length': String(file.size),
            'Upload-Metadata': metadataHeader,
            'Tus-Resumable': '1.0.0',
            ...(this.client['token'] ? {
              'Authorization': ` + "`" + `Bearer ${this.client['token']}` + "`" + `,
            } : {}),
          },
        },
      );

      if (!response.ok) {
        throw new Error(` + "`" + `Failed to create upload: ${response.status}` + "`" + `);
      }

      const location = response.headers.get('Location');
      if (!location) {
        throw new Error('No Location header in response');
      }

      return location.split('/').pop()!;
    };

    const uploadChunk = async (): Promise<void> => {
      if (!uploadId || paused || canceled) return;

      const chunk = file.slice(offset, offset + chunkSize);
      const response = await fetch(
        ` + "`" + `${this.client['url']}/api/files/${bucket}/tus/${uploadId}` + "`" + `,
        {
          method: 'PATCH',
          headers: {
            'Content-Type': 'application/offset+octet-stream',
            'Upload-Offset': String(offset),
            'Tus-Resumable': '1.0.0',
            ...(this.client['token'] ? {
              'Authorization': ` + "`" + `Bearer ${this.client['token']}` + "`" + `,
            } : {}),
          },
          body: chunk,
        },
      );

      if (!response.ok) {
        throw new Error(` + "`" + `Failed to upload chunk: ${response.status}` + "`" + `);
      }

      const newOffset = parseInt(response.headers.get('Upload-Offset') || '0', 10);
      offset = newOffset;

      if (progressCallback) {
        progressCallback((offset / file.size) * 100);
      }

      if (offset < file.size && !paused && !canceled) {
        await uploadChunk();
      }
    };

    const getMetadata = async (): Promise<FileMetadata> => {
      if (!uploadId) {
        throw new Error('Upload not started');
      }

      const response = await fetch(
        ` + "`" + `${this.client['url']}/api/files/${bucket}/tus/${uploadId}` + "`" + `,
        {
          method: 'HEAD',
          headers: {
            'Tus-Resumable': '1.0.0',
            ...(this.client['token'] ? {
              'Authorization': ` + "`" + `Bearer ${this.client['token']}` + "`" + `,
            } : {}),
          },
        },
      );

      if (!response.ok) {
        throw new Error(` + "`" + `Failed to get upload status: ${response.status}` + "`" + `);
      }

      offset = parseInt(response.headers.get('Upload-Offset') || '0', 10);

      if (offset >= file.size) {
        const listResponse = await this.list(bucket, { limit: 1 });
        return listResponse.items[0];
      }

      throw new Error('Upload not complete');
    };

    return {
      async start(): Promise<FileMetadata> {
        uploadId = await createUpload();
        await uploadChunk();
        return getMetadata();
      },

      pause(): void {
        paused = true;
      },

      resume(): void {
        paused = false;
        uploadChunk().catch(console.error);
      },

      async cancel(): Promise<void> {
        if (!uploadId) return;
        canceled = true;

        await fetch(
          ` + "`" + `${this.client['url']}/api/files/${bucket}/tus/${uploadId}` + "`" + `,
          {
            method: 'DELETE',
            headers: {
              'Tus-Resumable': '1.0.0',
              ...(this.client['token'] ? {
                'Authorization': ` + "`" + `Bearer ${this.client['token']}` + "`" + `,
              } : {}),
            },
          },
        );
      },

      onProgress(callback: (progress: number) => void): void {
        progressCallback = callback;
      },
    };
  }
}

`)
}
